# Motion-Detection-in-Static-Security-Cameras-


Background information and Algorithm used:-

Background Substraction is a technique for separating out foreground elements from the background and
is done by generating a foreground mask. This technique is used for detecting dynamically moving objects
from static cameras. Background subtraction technique is important for object tracking. There are severaltechniques for background subtraction
The running average of a function is used to separate foreground from background. In this concept, the video sequence is analyzed over a particular 
set of frames. During this sequence of frames, the running average over the current frame and the previous frames is computed. This gives us the background 
model and any new object introduced in the during the sequencing of the video becomes the part of the foreground. Then, the current frame holds the newly 
introduced object with the background. Then the computation of the absolute difference between the background model (which is a function of time) and the 
current frame (which is newly introduced object) is done.
There are no effective clinical treatments to restore vision for some retinal diseases such as age- related macular degeneration and retinitis pigmentosa. 
Implanting a visual prosthesis has been proposed as a viable approach to restore partial vision to blind patients suffering from these diseases. The perception 
of spots of light, called phosphenes, are elicited by electrically stimulating different parts of the visual pathway (retina, optic nerve, or cortex). Over recent 
decades, several research groups have developed different types of visual prosthetic devices and successfully implanted them in blind patients. Although visual
prostheses have gained significant development and continue to achieve encouraging improvement, some engineering challenges, such as electrode fabrication, power
consumption, and long-term viability, remain to be overcome before microelectronic high density electrode implants can be realized. Consequently, visual perception 
generated by a limited number of stimulation contacts is still poor relative to normal vision. Methods to optimize the image quality presented by such a limited 
number of phosphene dots to maximize visual percepts are currently being considered. Background subtraction is process of extracting foreground objects from 
maintained background model. A foreground object is any entity that detected by producing difference of the every frame of sequence to background model. This 
result can be further used for tracking targets, motion detection. Background subtraction further divides into parametric and non- parametric background 
subtraction. There are different background subtractions techniques have been proposed in literature. The background model can be static or dynamic. The 
flowchart for Background subtraction is shown in figure 4. Dynamic background model is one in which the background of scene may contain moving objects in 
outdoor environment, Pixel-based and block based are two major kind of approached are for background Subtraction. To construct a statistical representation
of background scene non-parametric statistical Modelling of pixel process is used. The different challenges that have to face to construct a good background
subtraction algorithm are robustness against the changes in illumination and shadow detection.
Background subtraction is a widely used approach for detecting moving objects in videos from static cameras. The rationale in the approach is that of detecting
the moving objects from the difference between the current frame and a reference frame, often called the “background image”, or “background model”. As a baric,
the background image must be a representation of the scene with no moving objects and must be kept regularly updated so as to adapt to the varying luminaries 
conditions and geometry settings. More complex models have extended the concept of “background subtraction” beyond its literal meaning. Several methods for
performing background subtraction have been proposed in the recent literary. All of these methods try to effectively estimate the background model from the
temporal sequence of the frames. However, there is a wide variety of techniques and both the expert and the newcomer to this area can be confused about the 
benefits and limitations of each method. This paper provides a thorough review of the main methods (with inevitable exclusions due to space restrictions) and
an original categorisation based on speed, memory requirements and accuracy

   
 Motion Detection Methods
The video surveillance has long been in use for monitoring security sensitive areas for examples banks, department stores, traffic monitoring on highway, public 
places which are crowded. Due to the advanced technology the large capability of storage devices are available. The motion detection methods are classified 
according to the method of finding moving object. Different motion detection methods are described as follows:
Frame differencing: The Frame differencing method uses the two or three adjacent frame based on time series image to subtract and gets difference images, its
working is very similar to background subtraction after the subtraction of image it gives moving target information through the threshold value. This method 
is simple and easy to implement, and also it is similar to the background subtraction. But this method is highly adaptive to dynamic scene changes, however, 
it generally fails in detecting whole relevant pixels of some types of moving objects. Additional methods need to be adopted in order to detect stopped objects
for the success of higher level are computationally complex and cannot be used real-time without specialized hardware.
The basic principle in the background subtraction technique is separating the estimated image from the observed image. The observed image is modeled as the
background while the estimated image contains suitable objects known as foreground. This foreground process divides the image into two complementary sets of 
pixels, a foreground containing suitable objects and a background containing static area.
There are certain criteria which every detection algorithm must fulfill. Any background detection algorithm must adapt itself to sudden changes like illumination
changes, motion changes, high frequency objects and their geometry especially while catering to outdoor surveillance scenes[8]. These include unfamiliar changes
in light intensity, camera oscillations, objects like trees and parked vehicles. Most challenging applications require the algorithms to be implemented and 
incorporated in the camera itself to reduce the computational load later on.
28
   
         Let Image be represented as F(x,y,t) and Background as K(x,y,t) at time t. Using Frame Differencing method, background frame is represented as
         K(x,y,t) = F(x,y,t-1) The background can thus be estimated if
Background subtraction: it is particularly a commonly used technique for motion segmentation in static images. It will detect moving regions by subtracting
the current image pixel-by-pixel from a reference background image that is created by averaging images over time in an initialization period. The basic idea 
of background subtraction method is to initialize a background firstly, and then by subtracting current frame in which the moving object present that current
frame is subtracted with background frame to detect moving object. This method is simple and easy to realize, and accurately extracts the characteristics of 
target data, but it is sensitive to the change of external environment, so it is applicable to the condition that the background is known. Background subtraction
methods operate on pixels independently. One such method described in [9] advocates that neighboring pixels of background models must remain constant or show 
similar variations over time. This theory holds good as long as the pixels neighboring to each other belong to a single background object. For different background
objects it poses a difficult task for pixels distributed in their borders. All the pixels are divided into groups first of N ×N blocks and every block is
processed as a
2 component vector. Principal Component Analysis (PCA) model is computed for each block by collecting few samples over time [10]. Pixels are then classified
based on the threshold difference between current image and backspace projection of its PCA coefficients as either background or foreground. Independent 
Component Analysis (ICA) is similar to the above approach and is described in [11]. This method uses a demixing vector and compares it with a new image to 
separate foreground from background image taken as reference. This method is proved to be robust to indoor illumination changes.
Optical flow: The optical flow method uses the motion target of the vector characteristics which changed with time to detect motion area in image sequences. 
It gives better performance under the moving camera, but this algorithm is very complex and complicated computation and also it needs special hardware support,
so it is difficult to meet the requirements of real-time video processing.
Artificial neural networks [12] are also seen to be used by background models to learn its motion patterns through self organization. Compressive sensing 
techniques based Background subtraction algorithms are also seen to be actively used in areas concerning to medicine [13]. This framework allows background
to be represented in compressed form. This method detects object without the need for image reconstruction and
allowing the foreground objects to occupy a small portion in front of the camera for correct detection.
29
   
Evolving from this technique, sparse recovery problem is formulated [14] where each color channels in the video, which is modeled independently as a linear
combination of the same color channel for different
video frames. Each color channel’s scaling is found separately maintaining the general structure of the frame composition thus making it highly adaptive to 
illumination changes.
